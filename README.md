# municipal-scrape-workspace

This is a standalone Python package + git repo for the municipal scraping workflow.

This repo also contains Common Crawl (CC) index pipeline tooling (Parquet + DuckDB pointer indexes + meta-indexes). The CC tooling now lives under the installable package namespace `common_crawl_search_engine`.

## ğŸ“š Repository Structure

**âœ… REFACTORING / REORGANIZATION COMPLETE** - Code is split into two installable packages under `src/`:

- `common_crawl_search_engine` â€” Common Crawl indexing/search pipeline, unified `ccindex` CLI, dashboard, MCP server
- `municipal_scrape_workspace` â€” municipal scraping orchestrator + wrapper CLI

ğŸ‘‰ **Start Here**:

- [QUICKSTART.md](QUICKSTART.md)
- [docs/README.md](docs/README.md) (component docs index)

**Essential Documentation**:
- ğŸ¯ [docs/municipal_scrape_workspace/reorganization/REORGANIZATION_PLAN.md](docs/municipal_scrape_workspace/reorganization/REORGANIZATION_PLAN.md) â€” root directory cleanup plan/details
- ğŸ“˜ [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) â€” root wrapper removal + command migration map
- ğŸ“ [docs/common_crawl_search_engine/README.md](docs/common_crawl_search_engine/README.md) â€” CC tooling docs
- ğŸ“ [docs/municipal_scrape_workspace/README.md](docs/municipal_scrape_workspace/README.md) â€” municipal workflow docs

**Documentation Organization**:
- ğŸ“ [docs/municipal_scrape_workspace/](docs/municipal_scrape_workspace/) - Municipal scrape + refactoring docs
- ğŸ“ [docs/common_crawl_search_engine/](docs/common_crawl_search_engine/) - Common Crawl search engine docs
- ğŸ“ [docs/](docs/) - Top-level docs index

**Final Status** (2026-01-20):
- âœ… **52 Python files processed** (100% complete)
- âœ… **41 files migrated** to `src/` (canonical implementations)
- âœ… **11 files archived** in `archive/ccindex/superseded/`
- âœ… **Root directory cleaned** - 73 files removed (32 shell wrappers + 41 Python wrappers)
- âœ… **Data organized** - CSV files moved to `data/` directory
- âœ… **Clean package structure** - follows Python best practices
- âœ… **Proper imports** - no sys.path hacks
- âœ… **Installable package** - works with `pip install -e .`
- âœ… **Console script entry points** - 12+ command-line tools available
- âœ… **Comprehensive documentation** - complete structure guide + migration guide

## Quickstart

```bash
# 1. Setup environment
./bootstrap.sh
source .venv/bin/activate

# 2. Install package (basic)
pip install -e .

# 3. (Optional) Install with CC index tooling dependencies
pip install -e '.[ccindex]'

# 4. Run tools - Two methods:

# Method A: Via Python modules
python -m common_crawl_search_engine.ccindex.search_cc_domain --domain example.com
python -m common_crawl_search_engine.ccindex.build_cc_pointer_duckdb --help

# Method B: Via console scripts (shorter, after pip install)
ccindex-search-domain --domain example.com
ccindex-build-pointer --help
municipal-scrape --help

# 5. Run operational scripts:

# All shell scripts are in scripts/ops/ directory
scripts/ops/download_cc_indexes.sh
scripts/ops/overnight_build_duckdb_index.sh
scripts/ops/monitor_progress.sh
```

**ğŸ“š For current structure, see [docs/REPO_STRUCTURE.md](docs/REPO_STRUCTURE.md)**

## Directory Structure

```
municipal_scrape_workspace/
â”œâ”€â”€ bootstrap.sh                     # Setup script
â”œâ”€â”€ pyproject.toml                   # Package configuration
â”œâ”€â”€ data/                            # Reference data files
â”‚   â””â”€â”€ us_towns_and_counties_urls.csv
â”œâ”€â”€ src/                             # Canonical Python packages (src-layout)
â”‚   â”œâ”€â”€ common_crawl_search_engine/  # Common Crawl tooling (ccindex core + CLI/dashboard/MCP)
â”‚   â””â”€â”€ municipal_scrape_workspace/  # Municipal scraping tooling
â”œâ”€â”€ scripts/ops/                     # All operational shell scripts
â”‚   â”œâ”€â”€ download_cc_indexes.sh
â”‚   â”œâ”€â”€ overnight_build_*.sh
â”‚   â””â”€â”€ ... (30+ scripts)
â”œâ”€â”€ docs/                            # Documentation
â”œâ”€â”€ tests/                           # Test suite
â””â”€â”€ archive/                         # Archived/superseded files
```

**Note**: 
- All Python tools are accessed via Python modules or console scripts (see [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md))
- Shell scripts are in `scripts/ops/` directory

## Publishing

- Repository: https://github.com/endomorphosis/municipal_scrape_workspace
- Default branch: `main`
- Push changes:

```bash
git checkout main
git pull --rebase
git add -A
git commit -m "Your change"
git push
```

- If you prefer a PR workflow:

```bash
git checkout -b feature/your-branch
git push -u origin feature/your-branch
# Open a PR against main
```
