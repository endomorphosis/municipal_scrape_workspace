[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "municipal-scrape-workspace"
version = "0.1.0"
description = "Municipal scraping workspace that depends on ipfs_datasets_py"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
  # ipfs_datasets_py has submodule issues when installing from git
  # Making it optional - install with: pip install -e '.[ipfs]'
  # Or set IPFS_DATASETS_PY_ROOT env var to local checkout
]

[project.optional-dependencies]
# Optional: IPFS datasets integration
ipfs = [
  "ipfs_datasets_py @ git+https://github.com/endomorphosis/ipfs_datasets_py.git@main",
]
# Optional: enable extra fallbacks like Playwright (you still need `playwright install chromium`).
playwright = ["playwright>=1.45"]

# Optional: Common Crawl (CC) index pipeline tooling (DuckDB + Parquet)
ccindex = [
  "duckdb>=0.10.0",
  "pyarrow>=14.0.0",
  "psutil>=5.9.0",
  "requests>=2.31.0",
]

# Optional: MCP server for ccindex (stdio JSON-RPC)
ccindex-mcp = [
  "mcp>=1.0.0",
]

# Optional: local web dashboard for ccindex
ccindex-dashboard = [
  "fastapi>=0.110.0",
  "uvicorn>=0.27.0",
  "psutil>=5.9",
]

# Development dependencies (testing, linting, formatting)
dev = [
  "pytest>=7.0",
  "pytest-cov>=4.0",
  "pytest-asyncio>=0.21",
  "black>=23.0",
  "ruff>=0.1.0",
  "mypy>=1.0",
]

[project.scripts]
# Main CLI
municipal-scrape = "municipal_scrape_workspace.cli:main"

# Unified CCIndex CLI + MCP server
ccindex = "common_crawl_search_engine.cli:main"
ccindex-mcp = "common_crawl_search_engine.mcp_server:main"
ccindex-dashboard = "common_crawl_search_engine.dashboard:main"

# Common Crawl search tools
ccindex-search = "common_crawl_search_engine.ccindex.search_cc_via_meta_indexes:main"
ccindex-search-domain = "common_crawl_search_engine.ccindex.search_cc_domain:main"
ccindex-search-parallel = "common_crawl_search_engine.ccindex.search_parallel_duckdb_indexes:main"

# Index building tools
ccindex-build-pointer = "common_crawl_search_engine.ccindex.build_cc_pointer_duckdb:main"
ccindex-build-parallel = "common_crawl_search_engine.ccindex.build_parallel_duckdb_indexes:main"
ccindex-build-meta = "common_crawl_search_engine.ccindex.build_year_meta_indexes:main"

# Orchestration tools
ccindex-orchestrate = "common_crawl_search_engine.ccindex.cc_pipeline_orchestrator:main"
ccindex-watch = "common_crawl_search_engine.ccindex.cc_pipeline_watch:main"
ccindex-hud = "common_crawl_search_engine.ccindex.cc_pipeline_hud:main"

# Validation tools
ccindex-validate = "common_crawl_search_engine.ccindex.validate_collection_completeness:main"
ccindex-validate-parquet = "common_crawl_search_engine.ccindex.validate_and_sort_parquet:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
